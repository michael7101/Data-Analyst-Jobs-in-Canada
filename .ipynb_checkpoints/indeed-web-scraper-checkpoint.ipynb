{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c36a4e8-3c46-410f-bac2-6775c32cafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "import re\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77983e15-7352-49b8-af9b-7e6efda3d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselink = \"https://ca.indeed.com\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fbb4f0e-e32d-477f-9ca4-3f7de2b0368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Title', 'Location', 'Extract_date', 'Link', 'Desc', \n",
    "                           'Company', 'CompanyLink', 'Salary', 'Job_Type',\n",
    "                           'Remote', 'Reviews', 'Stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0705443-9b9f-4d6c-8347-446a848ba9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ca.indeed.com/jobs?q=data+analyst&l=canada&fromage=1\n"
     ]
    }
   ],
   "source": [
    "# Generate url from position, location and date posted.\n",
    "def get_url(position, location, dateposted):\n",
    "    template = 'https://ca.indeed.com/jobs?q={}&l={}&fromage={}'\n",
    "    position = position.replace(' ', '+')\n",
    "    location = location.replace(' ', '+')\n",
    "    dateposted = dateposted.replace(' ', '+')\n",
    "    url = template.format(position, location, dateposted)\n",
    "    return url\n",
    "url = get_url('data analyst', 'canada', '1')\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cecdee5b-ac8f-424d-a41f-34aee7507756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(url, headers = headers)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "pages = soup.find(id=\"searchCountPages\").get_text().strip()\n",
    "pages = pages.replace(\"Page 1 of \", \"\")\n",
    "pages = pages.replace(\" jobs\", \"\")\n",
    "X = (int(math.ceil(int(pages)/15)))*10\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c7208e-248a-4744-95e6-2523134493fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in range(0, X, 10):\n",
    "    links = url+'&start={}'.format(number)\n",
    "    r = requests.get(links, headers = headers)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    jobcards = soup.find(\"div\", attrs={\"id\": \"mosaic-zone-jobcards\"})\n",
    "    links = []\n",
    "    \n",
    "    for l in jobcards.find_all('a', attrs={'href': re.compile(\"vjs=3\")}):\n",
    "        links.append(l.get('href'))\n",
    "        \n",
    "    for n in links:\n",
    "        newlink = baselink + str(n)\n",
    "        r = requests.get(newlink, headers = headers)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        extract_date = datetime.today().strftime('%Y-%m-%d')\n",
    "        loc = soup.find(class_=\"icl-u-xs-mt--xs icl-u-textColor--secondary jobsearch-JobInfoHeader-subtitle jobsearch-DesktopStickyContainer-subtitle\")\n",
    "        com = soup.find(class_=\"jobsearch-CompanyInfoContainer\")\n",
    "        sal = soup.find(class_=\"jobsearch-JobMetadataHeader-item\")\n",
    "        rat = soup.find(class_=\"icl-u-lg-block icl-u-lg-mr--sm icl-u-xs-hide\")\n",
    "        \n",
    "        try:\n",
    "            reviews = rat.find('div', string=re.compile(\"reviews\")).text.strip()\n",
    "        except AttributeError:\n",
    "            reviews = \"NA\"\n",
    "                        \n",
    "        try:\n",
    "            stars = rat.select_one('meta[content]')['content']\n",
    "        except AttributeError:\n",
    "            stars = \"NA\"\n",
    "                        \n",
    "        try:\n",
    "            desc = soup.find(class_=\"jobsearch-jobDescriptionText\").text.strip()\n",
    "        except AttributeError:\n",
    "            desc = \"NA\"\n",
    "                        \n",
    "        try:\n",
    "            job_title = soup.find(class_=\"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title\").text.strip()\n",
    "        except AttributeError:\n",
    "            job_title = \"NA\"\n",
    "                        \n",
    "        try:\n",
    "            job_type = sal.find('span', string=re.compile(\"Full|Part|Casu|Intern|Perman|Contr|term|Temp|Freel|Apprent\")).text.strip()\n",
    "        except AttributeError:\n",
    "            job_type = \"NA\"\n",
    "            \n",
    "        try:\n",
    "            remote = loc.find('div', string=re.compile(\"Remote|remote\")).text.strip()\n",
    "        except AttributeError:\n",
    "            remote = \"NA\"\n",
    "                        \n",
    "        try:\n",
    "            salary = sal.find('span', string=re.compile(\"year|hour\")).text.strip()\n",
    "        except AttributeError:\n",
    "            salary = \"NA\"\n",
    "                        \n",
    "        try:\n",
    "            companylink = com.find('a', attrs={'href': re.compile(\"//\")}).get('href')\n",
    "        except AttributeError:\n",
    "            companylink = \"NA\"\n",
    "                        \n",
    "        try:\n",
    "            company = com.find('a', attrs={'href': re.compile(\"//\")}).string.strip()\n",
    "        except AttributeError:\n",
    "            company = \"NA\"\n",
    "                        \n",
    "        try:\n",
    "            location = loc.find('div', string=re.compile(\"ON|SK|BC|AB|PE|NS|MB|QC|NL|PE|YT|NB|NT|NU\")).string.strip()\n",
    "        except AttributeError:\n",
    "            location = \"NA\"\n",
    "                        \n",
    "        df.loc[len(df.index)] = [job_title, location, extract_date,  newlink, desc, company, companylink, salary, job_type, remote, reviews, stars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e5f236-8588-4529-ab22-4efddf05f8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indeedjobs2022-04-09.csv\n"
     ]
    }
   ],
   "source": [
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "fileName = \"indeedjobs\" + date + \".csv\" \n",
    "print(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c83b9c1-c9d1-4437-8e37-e4b4c8122757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(fileName, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ed78a-143c-4205-b537-65c5ef0bdf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8694fd-eb20-42f4-8222-2014237dcc79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
